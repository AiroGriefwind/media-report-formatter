import streamlit as st
import tempfile
import traceback
from datetime import datetime
from selenium.webdriver.support.ui import WebDriverWait

import pytz
import re

HKT = pytz.timezone("Asia/Hong_Kong")

from utils.wisers_utils import (
    setup_webdriver,
    perform_login,
    switch_language_to_traditional_chinese,
    robust_logout_request,
    set_date_range_period,
    is_hkt_monday,
    go_back_to_search_form,
    wait_for_search_results,
    ensure_results_list_visible,
    wait_for_results_panel_ready,
    search_title_from_home,
    search_title_via_edit_search_modal,
    set_media_filters_in_panel,
    set_keyword_scope_checkboxes,
    inject_cjk_font_css,
    scroll_to_load_all_content,
    wait_for_ajax_complete,
)
from utils.web_scraping_utils import scrape_hover_popovers
from utils import international_news_utils as intl_utils
from utils.firebase_logging import ensure_logger

# Reuse UI/state helpers from saved_search_news
from tabs.saved_search_news import (
    ensure_news_session_state,
    restore_progress,
    rollback_to_ui_sorting,
    build_grouped_data,
    render_article_card,
    _article_key_from_item,
    _article_key_from_scraped,
    _normalize_title,
    ensure_trimmed_docx_in_firebase_and_session,
)

parse_metadata = intl_utils.parse_metadata
scrape_articles_by_news_id = intl_utils.scrape_articles_by_news_id
extract_news_id_from_html = intl_utils.extract_news_id_from_html
create_international_news_report = intl_utils.create_international_news_report


HK_KEYWORD_DEFAULT = (
    "æå®¶è¶…/å±€é•·/å…¨æ¸¯/å¸é•·/è²¡æ”¿å¸/å¾‹æ”¿å¸/æ”¿å‹™å¸/è¡Œæ”¿æœƒè­°/å…¬å‹™å“¡/ç”³è¨´å°ˆå“¡å…¬ç½²/å»‰æ”¿å…¬ç½²/"
    "å¯©è¨ˆç½²/æ–‡åŒ–é«”è‚²åŠæ—…éŠå±€/æ•™è‚²å±€/ç’°å¢ƒåŠç”Ÿæ…‹å±€/é†«å‹™è¡›ç”Ÿå±€/æ—…ç™¼å±€/åº·æ¨‚åŠæ–‡åŒ–äº‹å‹™ç½²/"
    "æ¼è­·ç½²/é£Ÿç’°ç½²/è¡›ç”Ÿç½²/æ°‘æ”¿åŠé’å¹´äº‹å‹™å±€/å‹å·¥åŠç¦åˆ©å±€/å‹å·¥è™•/ç¤¾æœƒç¦åˆ©ç½²/ä¿å®‰å±€/æµ·é—œ/"
    "è­¦å‹™è™•/å…¥å¢ƒäº‹å‹™/é‡‘ç®¡å±€/å•†å‹™åŠç¶“æ¿Ÿç™¼å±•å±€/æŠ•è³‡æ¨å»£ç½²/ç™¼å±•å±€/åœ°æ”¿ç¸½ç½²/æˆ¿å±‹å±€/"
    "å‰µæ–°ç§‘æŠ€åŠå·¥æ¥­å±€/ç¨…å‹™å±€/æ•¸å­—è¾¦/å®¶æ—è¾¦å…¬å®¤/å‰µæ–°ç§‘æŠ€ç½²/é‹è¼¸åŠç‰©æµå±€/é‹è¼¸ç½²/æ°‘èˆª/"
    "è·¯æ”¿ç½²/æµ·äº‹è™•/æ©Ÿç®¡å±€/é‡‘ç®¡å±€/æ¢ä¾‹è‰æ¡ˆ/ä¸‰è®€/æ”¿åºœæ³•æ¡ˆ/åœ‹å®‰/å…¨é‹æœƒ/ç©©å®šå¹£/é ˜å±•/"
    "é›»å‹•è»Š/çš„å£«/æ›¸å±•/è¯æ‹›/æ–°ç”°ç§‘æŠ€åŸ"
)

INTERNATIONAL_KEYWORD_DEFAULT = (
    "åœ‹éš›/ç‰¹æœ—æ™®/å¤–äº¤éƒ¨/ä¸­ç¾/æ­ç¾/ä¸­æ±/ä¿„çƒ/ä¸­æ­/åŒ—ç´„/ä¸­ä¿„/å°å·´/ä»¥è‰²åˆ—/å·´ä»¥/è¯åˆåœ‹/"
    "ç¾è¯å„²/ä¸€å¸¶ä¸€è·¯/æ±ç›Ÿ/æ—¥æœ¬/éŸ“åœ‹/æ±å—äº/ç¾åœ‹/æ­ç›Ÿ/ä¿„ç¾…æ–¯/æ–°åŠ å¡/çŸ³æ²¹/æˆ°çˆ­/å³°æœƒ/"
    "åœ‹é˜²éƒ¨/ä¼Šæœ—/åŒ—ç´„/æŸ¬åŸ”å¯¨/æ³°åœ‹/è»æ–¹/é—œç¨…/è²¿æ˜“æˆ°/è¨ªå•/è‹±åœ‹/æ³•åœ‹/å®‰å…¨éƒ¨/æœ€é«˜æ³•é™¢/"
    "å°åº¦/äº”çœ¼è¯ç›Ÿ/é‡‘ç£šåœ‹å®¶/IMF"
)

GREATER_CHINA_KEYWORD_DEFAULT = (
    "ç¿’è¿‘å¹³/æå¼·/ç‹æ¯…/è¨ªè¯/å¤–äº¤éƒ¨/åœ‹å°è¾¦/æ¸¯æ¾³è¾¦/ä¸­è¯è¾¦/æŠ—æˆ°/ä¸€å¸¶ä¸€è·¯/äºæŠ•è¡Œ/ä¸­å¤®/"
    "äººæ°‘éŠ€è¡Œ/åœ‹å‹™é™¢/ä¸­ç§‘é™¢/ä¸­æ–¹/å¤–äº¤éƒ¨/åœ‹é˜²éƒ¨/å…©å²¸/ä¸è–›ç¥¥/å—æµ·/ä¸­ç´€å§”/çœå§”/åè…/"
    "è²ªæ±¡/èŠ¯ç‰‡/æ–°èƒ½æº/ç¥èˆŸ/é‡‘ç£š/ä¸­è­‰ç›£/å·´æ‹¿é¦¬é‹æ²³/ç¶“æ¿Ÿæ”¿ç­–"
)

MEDIA_FILTER_CONTAINER_SELECTOR = (
    "#accordion-queryfilter > div.panel.panel-default.panel-queryfilter-scope-publisher "
    "> div.panel-collapse.collapse.in > div > div:nth-child(3)"
)
MEDIA_FILTER_KEEP_LABELS = ["å ±åˆŠ", "ç¶œåˆæ–°è", "é¦™æ¸¯"]


def _get_credentials(prefix="hkkw"):
    """Helper function to get credentials from secrets or manual input"""
    try:
        group_name = st.secrets["wisers"]["group_name"]
        username = st.secrets["wisers"]["username"]
        password = st.secrets["wisers"]["password"]
        svc_dict = dict(st.secrets["firebase"]["service_account"])
        bucket = st.secrets.get("firebase", {}).get("storage_bucket") or f"{svc_dict['project_id']}.appspot.com"
        st.success("âœ… Credentials loaded from secrets")
        st.info(f"Group: {group_name}\n\nUsername: {username}\n\nPassword: ****\n\nFirebase Bucket: {bucket}")
        return group_name, username, password, bucket
    except (KeyError, AttributeError, st.errors.StreamlitAPIException):
        st.warning("âš ï¸ Secrets not found. Please enter credentials manually:")
        group_name = st.text_input("Group Name", value="SPRG1", key=f"{prefix}-group")
        username = st.text_input("Username", placeholder="Enter username", key=f"{prefix}-username")
        password = st.text_input("Password", type="password", placeholder="Enter password", key=f"{prefix}-password")
        bucket = None
        return group_name, username, password, bucket


def _get_api_key(prefix="hkkw"):
    """Helper function to get API key from secrets or manual input"""
    try:
        api_key = st.secrets["wisers"]["api_key"]
        st.success(f"âœ… 2Captcha API Key loaded: {api_key[:8]}...")
        return api_key
    except (KeyError, AttributeError, st.errors.StreamlitAPIException):
        st.warning("âš ï¸ API key not found in secrets")
        return st.text_input("2Captcha API Key", type="password", placeholder="Enter API key", key=f"{prefix}-api-key")


def _build_default_keyword_text(config):
    presets = config.get("keyword_presets") or []
    if presets:
        keywords = []
        for preset in presets:
            if isinstance(preset, dict):
                keywords.append(preset.get("keywords") or "")
            else:
                keywords.append(str(preset))
        return "\n".join([k for k in keywords if k.strip()])
    return config.get("default_keyword_text") or HK_KEYWORD_DEFAULT


def _parse_keyword_presets(raw_text: str):
    lines = [line.strip() for line in (raw_text or "").splitlines()]
    return [line for line in lines if line]


def _get_keyword_presets(prefix: str, config):
    default_text = _build_default_keyword_text(config)
    raw_text = st.session_state.get(f"{prefix}_keyword_text") or default_text
    presets = _parse_keyword_presets(raw_text)
    if not presets and default_text:
        presets = [default_text.strip()]
    return presets


def _is_item_in_period(item, period_name: str) -> bool:
    if period_name == "today":
        return item.get("day_tag") != "å‘¨æ—¥"
    if period_name == "yesterday":
        return item.get("day_tag") == "å‘¨æ—¥"
    return True


def _ensure_keyword_state(prefix: str, config):
    keyword_key = f"{prefix}_keyword_text"
    content_key = f"{prefix}_include_content"
    if keyword_key not in st.session_state:
        st.session_state[keyword_key] = _build_default_keyword_text(config)
    if content_key not in st.session_state:
        st.session_state[content_key] = False


def _render_keyword_controls(prefix: str, config):
    _ensure_keyword_state(prefix, config)
    keyword_key = f"{prefix}_keyword_text"
    content_key = f"{prefix}_include_content"

    st.subheader("ğŸ” æœç´¢è¨­å®šï¼ˆé—œéµè©ç›´æœï¼‰")
    st.checkbox(
        "åŒ…å«å…§æ–‡ï¼ˆé è¨­åªæœæ¨™é¡Œï¼‰",
        key=content_key,
        value=st.session_state.get(content_key, False),
    )
    st.text_area(
        "é—œéµè©ï¼ˆæ¯è¡Œä¸€çµ„ï¼Œçµ„å…§ç”¨ / åˆ†éš”ï¼‰",
        key=keyword_key,
        height=150,
    )


def _apply_search_filters(driver, wait, st_module, include_content: bool):
    set_media_filters_in_panel(
        driver=driver,
        wait=wait,
        st_module=st_module,
        keep_labels=MEDIA_FILTER_KEEP_LABELS,
        container_selector=MEDIA_FILTER_CONTAINER_SELECTOR,
    )
    set_keyword_scope_checkboxes(
        driver=driver,
        st_module=st_module,
        title_checked=True,
        content_checked=include_content,
    )


def run_keyword_search_task(
    driver,
    wait,
    st_module,
    keyword: str,
    include_content: bool,
    use_edit_modal: bool = False,
    logger=None,
    screenshot_dir=None,
):
    _apply_search_filters(driver, wait, st_module, include_content)
    inject_cjk_font_css(driver, st_module=st_module)
    if st_module:
        try:
            st_module.image(
                driver.get_screenshot_as_png(),
                caption="ğŸ” å·²å®Œæˆæœç´¢è®¾ç½®ï¼ˆåª’é«”ä¾†æº + æ¨™é¡Œ/å…§æ–‡ï¼‰",
            )
        except Exception as e:
            st_module.warning(f"æˆªå›¾å¤±è´¥ï¼š{e}")
    if use_edit_modal:
        search_title_via_edit_search_modal(
            driver=driver, wait=wait, st_module=st_module, keyword=keyword
        )
    else:
        search_title_from_home(
            driver=driver, wait=wait, st_module=st_module, keyword=keyword
        )

    if wait_for_search_results(
        driver=driver,
        wait=wait,
        st_module=st_module,
        logger=logger,
        screenshot_dir=screenshot_dir,
        loading_grace_seconds=25,
        verify_no_results_wait=6,
    ):
        wait_for_results_panel_ready(driver=driver, wait=wait, st_module=st_module)
        ensure_results_list_visible(driver=driver, wait=wait, st_module=st_module)
        scroll_to_load_all_content(driver=driver, st_module=st_module)
        wait_for_ajax_complete(driver, timeout=10)
        return {"no_results": False}
    return {"no_results": True}


def _handle_keyword_search_news_logic(config, group_name, username, password, api_key, run_headless, keep_browser_open, max_words, min_words, max_articles):
    prefix = config["prefix"]
    base_folder = config["base_folder"]
    category_label = config["category_label"]
    report_title = config["report_title"]

    today = datetime.now(HKT).strftime("%Y%m%d")
    fb_logger = st.session_state.get("fb_logger") or ensure_logger(st, run_context=config["tab_title"])
    ensure_news_session_state(fb_logger, prefix, category_label, base_folder)

    stage_key = f"{prefix}_stage"
    if stage_key not in st.session_state:
        st.session_state[stage_key] = "smart_home"

    if st.session_state.get(f"{prefix}_need_rerun", False):
        st.session_state[f"{prefix}_need_rerun"] = False
        st.rerun()

    if st.session_state[stage_key] == "smart_home":
        st.header(f"ğŸ§­ {config['header']} - æ™ºèƒ½é€²åº¦æ¢å¾©")
        st.info(f"ğŸ“ Firebase: `{base_folder}/{today}/` | {datetime.now().strftime('%H:%M')}")
        _render_keyword_controls(prefix, config)

        def check_today_progress():
            preview_exists = bool(fb_logger.load_json_from_date_folder("preview_articles.json", [], base_folder=base_folder))
            user_list_exists = bool(fb_logger.load_json_from_date_folder("user_final_list.json", {}, base_folder=base_folder))
            final_articles_exists = bool(fb_logger.load_json_from_date_folder("full_scraped_articles.json", [], base_folder=base_folder))

            total_preview = len(fb_logger.load_json_from_date_folder("preview_articles.json", [], base_folder=base_folder))
            total_user_list = sum(len(v) for v in fb_logger.load_json_from_date_folder("user_final_list.json", {}, base_folder=base_folder).values())

            return {
                "preview": preview_exists,
                "user_list": user_list_exists,
                "final_articles": final_articles_exists,
                "preview_count": total_preview,
                "user_list_count": total_user_list,
            }

        progress = check_today_progress()

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“„ é è¦½æ–‡ç« ", f"{progress['preview_count']} ç¯‡", "âœ…" if progress["preview"] else "âŒ")
        with col2:
            st.metric("ğŸ‘¤ ç”¨æˆ¶æ’åº", f"{progress['user_list_count']} ç¯‡", "âœ…" if progress["user_list"] else "âŒ")
        with col3:
            final_count = len(fb_logger.load_json_from_date_folder("full_scraped_articles.json", [], base_folder=base_folder))
            st.metric("âœ… æœ€çµ‚å…¨æ–‡", f"{final_count} ç¯‡", "âœ…" if progress["final_articles"] else "âŒ")

        st.divider()

        if progress["final_articles"]:
            st.success("ğŸ‰ **ä»Šæ—¥ä»»å‹™å·²100%å®Œæˆï¼ç«‹å³ä¸‹è¼‰æœ€çµ‚å ±å‘Š**")
            col_download, col_rollback = st.columns([0.7, 0.3])
            with col_download:
                if st.button(
                    "ğŸ“¥ ä¸‹è¼‰æœ€çµ‚ Word å ±å‘Šï¼ˆ100%é€²åº¦ï¼‰",
                    type="primary",
                    use_container_width=True,
                    key=f"{prefix}-smarthome-download-final",
                ):
                    restore_progress(fb_logger, prefix, "finished", base_folder, category_label)
            with col_rollback:
                if st.button(
                    "â†©ï¸ å›åˆ°50%è°ƒæ•´æ’åº",
                    type="secondary",
                    use_container_width=True,
                    key=f"{prefix}-smarthome-rollback",
                    on_click=rollback_to_ui_sorting,
                    args=(fb_logger, prefix, base_folder, category_label),
                ):
                    pass
        elif progress["user_list"]:
            st.warning("â³ **ä»Šæ—¥å·²å®Œæˆ50%ï¼ˆç”¨æˆ¶æ’åºï¼‰ï¼Œç¹¼çºŒå…¨æ–‡çˆ¬å–**")
            if st.button(
                "ğŸ‘¤ æ¢å¾©æ’åºç•Œé¢ç¹¼çºŒï¼ˆ50%é€²åº¦ï¼‰",
                type="primary",
                use_container_width=True,
                key=f"{prefix}-smarthome-resume-sort",
            ):
                restore_progress(fb_logger, prefix, "ui_sorting", base_folder, category_label)
        elif progress["preview"]:
            st.info(f"ğŸ§¾ æ‡¸æµ®é è¦½å·²å®Œæˆ ({progress['preview_count']} ç¯‡æ–‡ç« )")
            if st.button(
                f"ğŸ¯ å±•ç¤ºç›®å‰é è¦½é€²åº¦ ({progress['preview_count']} æ¢)",
                type="secondary",
                use_container_width=True,
                key=f"{prefix}-smarthome-show-preview",
            ):
                preview_list = fb_logger.load_json_from_date_folder("preview_articles.json", [], base_folder=base_folder)
                st.session_state[f"{prefix}_articles_list"] = preview_list
                st.session_state[f"{prefix}_pool_dict"] = build_grouped_data(preview_list, category_label)
                st.session_state[f"{prefix}_sorted_dict"] = {category_label: []}
                fb_logger.save_json_to_date_folder(st.session_state[f"{prefix}_sorted_dict"], "user_final_list.json", base_folder=base_folder)
                st.success("âœ… å·²è¿›å…¥é€‰æ‹©æ¨¡å¼ï¼šé»˜è®¤æœªé€‰æ‹©ï¼Œç‚¹å‡»ã€æ·»åŠ ã€åŠ å…¥å·²é€‰æ¸…å•ã€‚")
                st.session_state[stage_key] = "ui_sorting"
                st.rerun()
        else:
            st.success("ğŸ†• **ä»Šæ—¥å…¨æ–°ä»»å‹™ï¼Œé–‹å§‹æŠ“å–é è¦½**")
            if st.button(
                "ğŸš€ é–‹å§‹æ–°ä»»å‹™ï¼ˆ0%é€²åº¦ï¼‰",
                type="primary",
                use_container_width=True,
                key=f"{prefix}-smarthome-start-new",
            ):
                st.session_state[stage_key] = "init"
                st.rerun()

        st.divider()

        col_a, col_b, col_c = st.columns(3)
        with col_a:
            if st.button("ğŸ”„ å¿½ç•¥é€²åº¦é‡ä¾†", type="secondary", key=f"{prefix}-smarthome-ignore"):
                for key in [
                    stage_key,
                    f"{prefix}_sorted_dict",
                    f"{prefix}_final_articles",
                    f"{prefix}_articles_list",
                    f"{prefix}_pool_dict",
                    f"{prefix}_final_docx",
                    f"{prefix}_final_docx_trimmed",
                ]:
                    if key in st.session_state:
                        del st.session_state[key]
                st.session_state[stage_key] = "init"
                st.rerun()
        with col_b:
            if st.button("ğŸ“‹ æŸ¥çœ‹ JSON æ•¸æ“š", type="secondary", key=f"{prefix}-smarthome-view-json"):
                st.session_state[stage_key] = "data_viewer"
                st.rerun()

        return

    if st.session_state[stage_key] == "data_viewer":
        st.header("ğŸ“‹ JSON æ•¸æ“šæª¢è¦–")
        if st.button("è¿”å›é€²åº¦é ", key=f"{prefix}-data-viewer-back-top"):
            st.session_state[stage_key] = "smart_home"
            st.rerun()
        col1, col2, col3 = st.columns(3)
        with col1:
            st.json(fb_logger.load_json_from_date_folder("preview_articles.json", [], base_folder=base_folder))
        with col2:
            st.json(fb_logger.load_json_from_date_folder("user_final_list.json", {}, base_folder=base_folder))
        with col3:
            st.json(fb_logger.load_json_from_date_folder("full_scraped_articles.json", [], base_folder=base_folder))
        if st.button("è¿”å›é€²åº¦é ", key=f"{prefix}-data-viewer-back-bottom"):
            st.session_state[stage_key] = "smart_home"
            st.rerun()
        return

    if st.session_state[stage_key] == "await_sort_confirm":
        st.header("âœ… é è¦½å®Œæˆï¼Œç­‰å¾…ç¢ºèª")
        st.info("å·²å®Œæˆç™»å‡ºä¸¦é‡‹æ”¾ Sessionã€‚ç¢ºèªå¾Œå†é€²å…¥ 50% ç”¨æˆ¶æ’åºç•Œé¢ã€‚")
        col_left, col_right = st.columns([0.6, 0.4])
        with col_left:
            if st.button(
                "ğŸ‘¤ é€²å…¥ç”¨æˆ¶æ’åºï¼ˆ50%é€²åº¦ï¼‰",
                type="primary",
                use_container_width=True,
                key=f"{prefix}-confirm-sort",
            ):
                st.session_state[stage_key] = "ui_sorting"
                st.rerun()
        with col_right:
            if st.button(
                "â†©ï¸ è¿”å›é€²åº¦é ",
                type="secondary",
                use_container_width=True,
                key=f"{prefix}-confirm-sort-back",
            ):
                st.session_state[stage_key] = "smart_home"
                st.rerun()
        return

    try:
        if st.session_state[stage_key] == "init":
            _render_keyword_controls(prefix, config)
            if st.button("ğŸš€ é–‹å§‹ä»»å‹™ï¼šæŠ“å–é è¦½", key=f"{prefix}-init-start"):
                with st.spinner("ç¬¬ä¸€æ­¥ï¼šç™»éŒ„ Wisers ä¸¦æŠ“å–é è¦½..."):
                    driver = setup_webdriver(headless=run_headless, st_module=st)
                    if not driver:
                        return

                    wait = WebDriverWait(driver, 20)
                    perform_login(driver=driver, wait=wait, group_name=group_name, username=username, password=password, api_key=api_key, st_module=st)
                    switch_language_to_traditional_chinese(driver=driver, wait=wait, st_module=st)

                    keyword_presets = _get_keyword_presets(prefix, config)
                    include_content = bool(st.session_state.get(f"{prefix}_include_content", False))

                    is_monday = is_hkt_monday()
                    per_period_max = max(1, max_articles // 2) if is_monday else max_articles
                    periods = [("today", None)]
                    if is_monday:
                        periods.append(("yesterday", "å‘¨æ—¥"))

                    combined_raw = []
                    combined_filtered = []
                    has_run_search = False

                    for period_name, day_tag in periods:
                        if period_name != "today":
                            set_date_range_period(
                                driver=driver,
                                wait=wait,
                                st_module=st,
                                period_name=period_name,
                            )

                        for preset_index, keyword in enumerate(keyword_presets):
                            use_edit_modal = has_run_search or (period_name != "today") or (preset_index > 0)
                            search_meta = run_keyword_search_task(
                                driver=driver,
                                wait=wait,
                                st_module=st,
                                keyword=keyword,
                                include_content=include_content,
                                use_edit_modal=use_edit_modal,
                            )
                            has_run_search = True

                            rawlist = scrape_hover_popovers(
                                driver=driver, wait=wait, st_module=st, max_articles=per_period_max
                            ) or []
                            raw_count = len(rawlist)
                            for item in rawlist:
                                item["keyword_preset"] = keyword
                                item["keyword_preset_index"] = preset_index
                                if day_tag:
                                    item["day_tag"] = day_tag

                            if st:
                                st.info(f"âœ… {period_name} é è¨­ {preset_index + 1} æŠ“å–äº† {raw_count} ç¯‡æ‡¸åœé è¦½")

                            filtered_rawlist = []
                            for item in rawlist:
                                hover_text = item.get("hover_text", "")
                                word_matches = re.findall(r"(\\d+)\\s*å­—", hover_text)
                                if word_matches:
                                    word_count = int(word_matches[0])
                                    if min_words <= word_count <= max_words:
                                        filtered_rawlist.append(item)
                                    else:
                                        if st:
                                            st.write(f"å·²éæ¿¾: {item.get('title', 'Unknown')} ({word_count} å­—)")
                                else:
                                    filtered_rawlist.append(item)

                            filtered_count = len(filtered_rawlist)
                            if st:
                                st.info(f"ğŸ“Š {period_name} é è¨­ {preset_index + 1} å­—æ•¸éæ¿¾å¾Œå‰©é¤˜: {filtered_count} ç¯‡")

                            if search_meta.get("no_results", False):
                                st.warning(f"âš ï¸ {period_name} é è¨­ {preset_index + 1} æœç´¢ç»“æœä¸º 0 ç¯‡ã€‚")
                            elif raw_count == 0:
                                st.warning(f"âš ï¸ {period_name} é è¨­ {preset_index + 1} æœç´¢æœ‰ç»“æœï¼Œä½†æ‡¸æµ®çˆ¬å–ç‚º 0 ç¯‡ã€‚")
                            elif raw_count > 0 and filtered_count == 0:
                                st.warning(f"âš ï¸ {period_name} é è¨­ {preset_index + 1} æœç´¢æœ‰çµæœï¼Œä½†å…¨éƒ¨è¢«å­—æ•¸éæ¿¾æ¢ä»¶ç¯©æ‰ã€‚")

                            combined_raw.extend(rawlist)
                            combined_filtered.extend(filtered_rawlist)

                    st.info("æš«æ™‚ç™»å‡ºä»¥é‡‹æ”¾ Session...")
                    try:
                        robust_logout_request(driver, st)
                    except Exception as e:
                        st.warning(f"ç™»å‡ºæ™‚å‡ºç¾å•é¡Œ: {e}")
                    driver.quit()

                    rawlist = combined_filtered

                    preview_list = []
                    for i, item in enumerate(rawlist):
                        item["original_index"] = i
                        hover_html = item.get("hover_html", "")
                        item["news_id"] = extract_news_id_from_html(hover_html)

                        hover_text = item.get("hover_text", "")
                        if "\n" in hover_text:
                            lines = hover_text.split("\n", 2)
                            if len(lines) > 1 and lines[0].strip() == item.get("title", "").strip():
                                raw_meta = lines[1].strip()
                            else:
                                raw_meta = lines[0].strip()
                        else:
                            raw_meta = ""
                        item["formatted_metadata"] = parse_metadata(raw_meta)
                        preview_list.append(item)

                    grouped_data = build_grouped_data(preview_list, category_label)
                    st.session_state[f"{prefix}_articles_list"] = preview_list

                    fb_logger.save_json_to_date_folder(preview_list, "preview_articles.json", base_folder=base_folder)

                    st.session_state[f"{prefix}_pool_dict"] = grouped_data
                    st.session_state[f"{prefix}_sorted_dict"] = {category_label: []}
                    st.session_state[stage_key] = "await_sort_confirm"
                    st.info("âœ… é è¦½å·²å®Œæˆä¸¦å®Œæˆç™»å‡ºã€‚è«‹ç¢ºèªå¾Œé€²å…¥ 50% ç”¨æˆ¶æ’åºã€‚")
                    return

        if st.session_state[stage_key] == "ui_sorting":
            st.header("ğŸ“± æ–°èæ’åºèˆ‡ç¯©é¸")
            st.info(f"ğŸ’¾ è‡ªå‹•ä¿å­˜è‡³ Firebase: `{base_folder}/{today}/user_final_list.json`")

            col_g1, col_g2 = st.columns(2)
            with col_g1:
                if st.button("ğŸ”„ é‡æ–°é–‹å§‹ (æ¸…é™¤æ•¸æ“š)", key=f"{prefix}-ui-reset"):
                    st.session_state[stage_key] = "init"
                    st.rerun()
            with col_g2:
                if st.button("ğŸ’¾ æ‰‹å‹•ä¿å­˜æ’åº", key=f"{prefix}-ui-save"):
                    fb_logger.save_json_to_date_folder(st.session_state[f"{prefix}_sorted_dict"], "user_final_list.json", base_folder=base_folder)
                    st.success("âœ… å·²ä¿å­˜ç”¨æˆ¶æ’åºæ¸…å–®ï¼")

            st.write("---")

            total_articles = sum(len(v) for v in st.session_state[f"{prefix}_sorted_dict"].values())
            st.markdown(f"**ç¸½æ–‡ç« æ•¸: {total_articles}**")

            category_order = [category_label]
            for category in category_order:
                selected = st.session_state[f"{prefix}_sorted_dict"].get(category, [])
                pool_dict = st.session_state.get(f"{prefix}_pool_dict") or {}
                pool = pool_dict.get(category, [])

                if not selected and not pool:
                    continue

                with st.expander(f"{category}ï¼ˆå·²é€‰ {len(selected)} / å€™é€‰ {len(pool)}ï¼‰", expanded=True):
                    if selected:
                        st.caption("å·²é€‰ï¼ˆå¯æ’åºï¼‰")
                        for i, article in enumerate(selected):
                            render_article_card(prefix, article, i, category, len(selected), mode="selected")
                    else:
                        st.info("å½“å‰åœ°åŒºè¿˜æ²¡æœ‰å·²é€‰æ–‡ç« ã€‚")

                    if pool:
                        st.caption("å€™é€‰ï¼ˆç‚¹å‡»æ·»åŠ ï¼‰")
                        for j, article in enumerate(pool):
                            render_article_card(prefix, article, j, category, len(pool), mode="pool")

            st.write("---")
            if st.button(
                "âœ… ç¢ºèªæ’åºä¸¦é–‹å§‹å…¨æ–‡çˆ¬å–",
                type="primary",
                use_container_width=True,
                key=f"{prefix}-ui-confirm",
            ):
                fb_logger.save_json_to_date_folder(st.session_state[f"{prefix}_sorted_dict"], "user_final_list.json", base_folder=base_folder)
                st.success("ğŸ’¾ ç”¨æˆ¶æ’åºå·²è‡ªå‹•ä¿å­˜è‡³ Firebase")
                st.session_state[stage_key] = "final_scraping"
                st.rerun()

        if st.session_state[stage_key] == "final_scraping":
            st.header("â³ æœ€çµ‚è™•ç†ä¸­...")

            final_list = []
            for category in [category_label]:
                if category in st.session_state[f"{prefix}_sorted_dict"]:
                    final_list.extend(st.session_state[f"{prefix}_sorted_dict"][category])

            if not final_list:
                st.warning("æ²’æœ‰æ–‡ç« è¢«é¸ä¸­ã€‚")
                if st.button("è¿”å›", key=f"{prefix}-final-back"):
                    st.session_state[stage_key] = "ui_sorting"
                    st.rerun()
                return

            with st.spinner(f"æ­£åœ¨çˆ¬å– {len(final_list)} ç¯‡æ–‡ç« çš„å…¨æ–‡å…§å®¹..."):
                driver = None
                try:
                    driver = setup_webdriver(headless=run_headless, st_module=st)
                    wait = WebDriverWait(driver, 20)
                    perform_login(driver=driver, wait=wait, group_name=group_name, username=username, password=password, api_key=api_key, st_module=st)
                    switch_language_to_traditional_chinese(driver=driver, wait=wait, st_module=st)

                    keyword_presets = _get_keyword_presets(prefix, config)
                    include_content = bool(st.session_state.get(f"{prefix}_include_content", False))
                    extra_presets = []
                    for item in final_list:
                        preset = item.get("keyword_preset")
                        if preset and preset not in keyword_presets and preset not in extra_presets:
                            extra_presets.append(preset)
                    if not keyword_presets:
                        keyword_presets = extra_presets[:] if extra_presets else [HK_KEYWORD_DEFAULT]
                    elif extra_presets:
                        keyword_presets = keyword_presets + extra_presets

                    default_keyword = keyword_presets[0] if keyword_presets else HK_KEYWORD_DEFAULT
                    items_by_preset = {}
                    for item in final_list:
                        preset = item.get("keyword_preset") or default_keyword
                        items_by_preset.setdefault(preset, []).append(item)

                    is_monday = is_hkt_monday()
                    per_period_max = max(1, max_articles // 2) if is_monday else max_articles
                    if is_monday:
                        full_articles_data = []
                        has_run_search = False
                        periods = [("today", None), ("yesterday", "å‘¨æ—¥")]

                        for period_name, _day_tag in periods:
                            if period_name != "today":
                                set_date_range_period(
                                    driver=driver, wait=wait, st_module=st, period_name=period_name
                                )

                            for preset_index, keyword in enumerate(keyword_presets):
                                period_items = [
                                    item
                                    for item in items_by_preset.get(keyword, [])
                                    if _is_item_in_period(item, period_name)
                                ]
                                if not period_items:
                                    continue

                                use_edit_modal = has_run_search or (period_name != "today") or (preset_index > 0)
                                run_keyword_search_task(
                                    driver=driver,
                                    wait=wait,
                                    st_module=st,
                                    keyword=keyword,
                                    include_content=include_content,
                                    use_edit_modal=use_edit_modal,
                                )
                                has_run_search = True
                                wait_for_results_panel_ready(driver=driver, wait=wait, st_module=st)
                                ensure_results_list_visible(driver=driver, wait=wait, st_module=st)
                                full_articles_data.extend(
                                    scrape_articles_by_news_id(driver, wait, period_items, st_module=st)
                                )
                    else:
                        full_articles_data = []
                        has_run_search = False
                        for preset_index, keyword in enumerate(keyword_presets):
                            preset_items = items_by_preset.get(keyword, [])
                            if not preset_items:
                                continue
                            use_edit_modal = has_run_search or (preset_index > 0)
                            run_keyword_search_task(
                                driver=driver,
                                wait=wait,
                                st_module=st,
                                keyword=keyword,
                                include_content=include_content,
                                use_edit_modal=use_edit_modal,
                            )
                            has_run_search = True
                            wait_for_results_panel_ready(driver=driver, wait=wait, st_module=st)
                            ensure_results_list_visible(driver=driver, wait=wait, st_module=st)
                            full_articles_data.extend(
                                scrape_articles_by_news_id(driver, wait, preset_items, st_module=st)
                            )

                    scraped_keys = {_article_key_from_scraped(a) for a in (full_articles_data or [])}
                    scraped_titles = {
                        _normalize_title(a.get("title") or a.get("source_title") or "")
                        for a in (full_articles_data or [])
                    }
                    missing_items = []
                    for item in final_list:
                        key = _article_key_from_item(item)
                        if key in scraped_keys:
                            continue
                        title_norm = _normalize_title(item.get("title"))
                        if title_norm and title_norm in scraped_titles:
                            continue
                        missing_items.append(item)

                    if missing_items:
                        st.warning(f"âš ï¸ ç¬¬ä¸€è¼ªæœ€çµ‚çˆ¬å–ç¼ºå¤± {len(missing_items)} ç¯‡ï¼Œé–‹å§‹äºŒæ¬¡æœç´¢è£œçˆ¬...")
                        fb_logger.save_json_to_date_folder(
                            missing_items,
                            "missing_articles_round1.json",
                            base_folder=base_folder,
                        )

                        missing_round2 = []
                        try:
                            go_back_to_search_form(driver=driver, wait=wait, st_module=st)
                        except Exception:
                            pass

                        for idx, item in enumerate(missing_items):
                            title = item.get("title", "")
                            st.write(f"ğŸ” äºŒæ¬¡æœç´¢ ({idx+1}/{len(missing_items)}): {title[:50]}...")

                            if idx == 0:
                                _apply_search_filters(driver, wait, st, include_content)
                                search_title_from_home(
                                    driver=driver,
                                    wait=wait,
                                    keyword=title,
                                    st_module=st,
                                )
                            else:
                                search_title_via_edit_search_modal(
                                    driver=driver,
                                    wait=wait,
                                    keyword=title,
                                    st_module=st,
                                )

                            has_results = wait_for_search_results(driver=driver, wait=wait, st_module=st)
                            if not has_results:
                                missing_round2.append(item)
                                continue
                            wait_for_results_panel_ready(driver=driver, wait=wait, st_module=st)
                            ensure_results_list_visible(driver=driver, wait=wait, st_module=st)

                            retry_scraped = scrape_articles_by_news_id(driver, wait, [item], st_module=st)
                            if retry_scraped:
                                full_articles_data.extend(retry_scraped)
                            else:
                                missing_round2.append(item)

                        if missing_round2:
                            st.warning(f"âš ï¸ äºŒæ¬¡æœç´¢ä»ç¼ºå¤± {len(missing_round2)} ç¯‡ï¼Œå·²è¨˜éŒ„æ¸…å–®ã€‚")
                            fb_logger.save_json_to_date_folder(
                                missing_round2,
                                "missing_articles_round2.json",
                                base_folder=base_folder,
                            )

                    st.session_state[f"{prefix}_final_articles"] = full_articles_data
                    fb_logger.save_json_to_date_folder(full_articles_data, "full_scraped_articles.json", base_folder=base_folder)

                    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
                        out_path = create_international_news_report(
                            articles_data=full_articles_data,
                            output_path=tmp.name,
                            st_module=st,
                            report_title=report_title,
                        )
                        with open(out_path, "rb") as f:
                            docx_bytes = f.read()

                    st.session_state[f"{prefix}_final_docx"] = docx_bytes
                    fb_logger.save_final_docx_bytes_to_date_folder(docx_bytes, "final_report.docx", base_folder=base_folder)
                    st.session_state[stage_key] = "finished"
                    st.rerun()

                except Exception as e:
                    st.error(f"âŒ æœ€çµ‚çˆ¬å–å¤±æ•—: {e}")
                    st.code(traceback.format_exc())
                finally:
                    if driver:
                        try:
                            if not keep_browser_open:
                                driver.quit()
                        except Exception:
                            pass

        if st.session_state[stage_key] == "finished":
            st.header("âœ… ä»»å‹™å®Œæˆ")
            st.success("âœ… æœ€çµ‚å ±å‘Šå·²ç”Ÿæˆä¸¦ä¿å­˜è‡³ Firebase")
            ensure_trimmed_docx_in_firebase_and_session(fb_logger, prefix, base_folder)

            col1, col2 = st.columns(2)
            with col1:
                if st.session_state.get(f"{prefix}_final_docx"):
                    st.download_button(
                        "ğŸ“¥ ä¸‹è¼‰æœ€çµ‚å ±å‘Šï¼ˆå®Œæ•´ç‰ˆï¼‰",
                        data=st.session_state[f"{prefix}_final_docx"],
                        file_name=f"{config['file_prefix']}_{today}.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    )
            with col2:
                if st.session_state.get(f"{prefix}_final_docx_trimmed"):
                    st.download_button(
                        "ğŸ“¥ ä¸‹è¼‰æœ€çµ‚å ±å‘Šï¼ˆæ‘˜è¦ç‰ˆï¼‰",
                        data=st.session_state[f"{prefix}_final_docx_trimmed"],
                        file_name=f"{config['file_prefix']}_{today}_trimmed.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    )
    except Exception as e:
        st.error(f"âŒ ç³»ç»Ÿé”™è¯¯ï¼š{e}")
        st.code(traceback.format_exc())


def render_hong_kong_keyword_search_tab():
    st.subheader("ğŸ‡­ğŸ‡° é¦™æ¸¯æ”¿æ²»æ–°èï¼ˆé—œéµè©ç›´æœï¼‰")

    config = {
        "tab_title": "é¦™æ¸¯æ”¿æ²»æ–°èï¼ˆé—œéµè©ç›´æœï¼‰",
        "header": "é¦™æ¸¯æ”¿æ²»æ–°èï¼ˆé—œéµè©ç›´æœï¼‰",
        "base_folder": "hong_kong_keyword_search",
        "report_title": "æœ¬åœ°æ–°èæ‘˜è¦",
        "category_label": "æœ¬åœ°æ–°è",
        "prefix": "hkkw",
        "file_prefix": "LocalNewsKeywordReport",
        "default_keyword_text": HK_KEYWORD_DEFAULT,
    }

    group_name, username, password, _bucket = _get_credentials(config["prefix"])
    api_key = _get_api_key(config["prefix"])

    col4, col5, col6 = st.columns(3)
    with col4:
        run_headless = st.checkbox("Headless æ¨¡å¼", value=True, key="hkkw-headless")
    with col5:
        keep_browser_open = st.checkbox("ä»»åŠ¡å®Œæˆåä¿æŒæµè§ˆå™¨æ‰“å¼€", value=False, key="hkkw-keep-browser")
    with col6:
        max_articles = st.number_input("æœ€å¤šæŠ“å–ç¯‡æ•°", min_value=10, max_value=120, value=60, step=10, key="hkkw-max-articles")

    st.divider()

    col7, col8 = st.columns(2)
    with col7:
        min_words = st.number_input("æœ€å°‘å­—æ•°", min_value=0, max_value=5000, value=200, step=50, key="hkkw-min-words")
    with col8:
        max_words = st.number_input("æœ€å¤šå­—æ•°", min_value=50, max_value=10000, value=1000, step=50, key="hkkw-max-words")

    _handle_keyword_search_news_logic(
        config=config,
        group_name=group_name,
        username=username,
        password=password,
        api_key=api_key,
        run_headless=run_headless,
        keep_browser_open=keep_browser_open,
        max_words=max_words,
        min_words=min_words,
        max_articles=max_articles,
    )


def render_international_keyword_search_tab():
    st.subheader("ğŸŒ åœ‹éš›æ–°èï¼ˆé—œéµè©ç›´æœï¼‰")

    config = {
        "tab_title": "åœ‹éš›æ–°èï¼ˆé—œéµè©ç›´æœï¼‰",
        "header": "åœ‹éš›æ–°èï¼ˆé—œéµè©ç›´æœï¼‰",
        "base_folder": "international_keyword_search",
        "report_title": "åœ‹éš›æ–°èæ‘˜è¦",
        "category_label": "åœ‹éš›æ–°è",
        "prefix": "intkw",
        "file_prefix": "InternationalKeywordReport",
        "default_keyword_text": INTERNATIONAL_KEYWORD_DEFAULT,
    }

    group_name, username, password, _bucket = _get_credentials(config["prefix"])
    api_key = _get_api_key(config["prefix"])

    col4, col5, col6 = st.columns(3)
    with col4:
        run_headless = st.checkbox("Headless æ¨¡å¼", value=True, key="intkw-headless")
    with col5:
        keep_browser_open = st.checkbox("ä»»åŠ¡å®Œæˆåä¿æŒæµè§ˆå™¨æ‰“å¼€", value=False, key="intkw-keep-browser")
    with col6:
        max_articles = st.number_input("æœ€å¤šæŠ“å–ç¯‡æ•°", min_value=10, max_value=120, value=60, step=10, key="intkw-max-articles")

    st.divider()

    col7, col8 = st.columns(2)
    with col7:
        min_words = st.number_input("æœ€å°‘å­—æ•°", min_value=0, max_value=5000, value=200, step=50, key="intkw-min-words")
    with col8:
        max_words = st.number_input("æœ€å¤šå­—æ•°", min_value=50, max_value=10000, value=1000, step=50, key="intkw-max-words")

    _handle_keyword_search_news_logic(
        config=config,
        group_name=group_name,
        username=username,
        password=password,
        api_key=api_key,
        run_headless=run_headless,
        keep_browser_open=keep_browser_open,
        max_words=max_words,
        min_words=min_words,
        max_articles=max_articles,
    )


def render_greater_china_keyword_search_tab():
    st.subheader("ğŸ€„ å¤§ä¸­è¯æ–°èï¼ˆé—œéµè©ç›´æœï¼‰")

    config = {
        "tab_title": "å¤§ä¸­è¯æ–°èï¼ˆé—œéµè©ç›´æœï¼‰",
        "header": "å¤§ä¸­è¯æ–°èï¼ˆé—œéµè©ç›´æœï¼‰",
        "base_folder": "greater_china_keyword_search",
        "report_title": "å¤§ä¸­è¯æ–°èæ‘˜è¦",
        "category_label": "å¤§ä¸­è¯æ–°è",
        "prefix": "gckw",
        "file_prefix": "GreaterChinaKeywordReport",
        "default_keyword_text": GREATER_CHINA_KEYWORD_DEFAULT,
    }

    group_name, username, password, _bucket = _get_credentials(config["prefix"])
    api_key = _get_api_key(config["prefix"])

    col4, col5, col6 = st.columns(3)
    with col4:
        run_headless = st.checkbox("Headless æ¨¡å¼", value=True, key="gckw-headless")
    with col5:
        keep_browser_open = st.checkbox("ä»»åŠ¡å®Œæˆåä¿æŒæµè§ˆå™¨æ‰“å¼€", value=False, key="gckw-keep-browser")
    with col6:
        max_articles = st.number_input("æœ€å¤šæŠ“å–ç¯‡æ•°", min_value=10, max_value=120, value=60, step=10, key="gckw-max-articles")

    st.divider()

    col7, col8 = st.columns(2)
    with col7:
        min_words = st.number_input("æœ€å°‘å­—æ•°", min_value=0, max_value=5000, value=200, step=50, key="gckw-min-words")
    with col8:
        max_words = st.number_input("æœ€å¤šå­—æ•°", min_value=50, max_value=10000, value=1000, step=50, key="gckw-max-words")

    _handle_keyword_search_news_logic(
        config=config,
        group_name=group_name,
        username=username,
        password=password,
        api_key=api_key,
        run_headless=run_headless,
        keep_browser_open=keep_browser_open,
        max_words=max_words,
        min_words=min_words,
        max_articles=max_articles,
    )
