import streamlit as st
import tempfile
import time
import traceback
from datetime import datetime
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By

import pytz  # âœ… æ–°å¢ TODAY ç”¨

import re

import json, tempfile, os

HKT = pytz.timezone('Asia/Hong_Kong')
TODAY = datetime.now(HKT).strftime("%Y%m%d")  # âœ… å…¨åŸŸ TODAY

# å¼•å…¥ AI å·¥å…·
from utils.ai_screening_utils import run_ai_screening

# å¼•å…¥é…ç½®å¸¸æ•¸
from utils.config import LOCATION_ORDER

# å¼•å…¥ Wisers å·¥å…·
from utils.wisers_utils import (
    setup_webdriver,
    perform_login,
    switch_language_to_traditional_chinese,
    logout,
    robust_logout_request,
)
from utils.web_scraping_utils import scrape_hover_popovers
from utils.international_news_utils import (
    run_international_news_task,
    create_hover_preview_report,
    should_scrape_article_based_on_metadata,
    scrape_specific_articles_by_indices,
    scrape_articles_by_news_id,  
    extract_news_id_from_html, 
    parse_metadata,
    create_international_news_report
)

from utils.intl_trim_utils import trim_docx

# å¼•å…¥ Firebase Logger
from utils.firebase_logging import ensure_logger

# âœ… åˆå§‹åŒ– loggerï¼ˆä¿®æ­£ï¼šç¢ºä¿ st å·²å­˜åœ¨ï¼‰
if 'fb_logger' not in st.session_state:
    st.session_state['fb_logger'] = ensure_logger(st, run_context="international_news")
fb_logger = st.session_state['fb_logger']

# âœ… ä¿®æ­£ï¼šsession_state åˆå§‹åŒ–ç§»åˆ°é€™è£¡ï¼Œä¸”åŠ  TODAY
if 'intl_articles_list' not in st.session_state:
    # è¼‰å…¥æ—¢æœ‰è³‡æ–™
    st.session_state.intl_articles_list = fb_logger.load_json_from_date_folder('preview_articles.json', [])
    st.session_state.intl_sorted_dict = fb_logger.load_json_from_date_folder('user_final_list.json', {})
    st.session_state.intl_final_articles = fb_logger.load_json_from_date_folder('full_scraped_articles.json', [])
    if st.session_state.intl_articles_list:
        st.success(f"âœ… å·²è¼‰å…¥ä»Šæ—¥ {TODAY} é è¦½è³‡æ–™ï¼Œé¿å…é‡çˆ¬ï¼")
        st.info(f"ğŸ“ Firebase è·¯å¾‘: international_news/{TODAY}/")

# === UI è¼”åŠ©å‡½æ•¸  ===

# ğŸ”¥ æ™ºèƒ½æª¢æŸ¥ä»Šæ—¥é€²åº¦å‡½æ•¸
def check_today_progress():
    """æª¢æŸ¥ Firebase ä¸­ä»Šæ—¥ä¸‰å€‹æ–‡ä»¶çš„å­˜åœ¨ç‹€æ…‹"""
    preview_exists = bool(fb_logger.load_json_from_date_folder('preview_articles.json', []))
    user_list_exists = bool(fb_logger.load_json_from_date_folder('user_final_list.json', {}))
    final_articles_exists = bool(fb_logger.load_json_from_date_folder('full_scraped_articles.json', []))
    
    total_preview = len(fb_logger.load_json_from_date_folder('preview_articles.json', []))
    total_user_list = sum(len(v) for v in fb_logger.load_json_from_date_folder('user_final_list.json', {}).values())
    
    return {
        'preview': preview_exists,
        'user_list': user_list_exists,
        'final_articles': final_articles_exists,
        'preview_count': total_preview,
        'user_list_count': total_user_list
    }

 # æ–‡ç« é€‰æ‹©æ± ç›¸å…³å‡½æ•°

def article_uid(article: dict) -> str:
    """Stable uid for cross-rerun button keys and de-dup."""
    return (
        article.get("news_id")
        or article.get("newsid")
        or article.get("url")
        or str(article.get("original_index", "na"))
    )

def build_grouped_data(article_list: list, location_order: list) -> dict:
    """
    Rebuild grouped dict using the same logic you already use:
    main_location -> location; is_tech_news -> Tech News; fallback Others.
    """
    grouped = {loc: [] for loc in location_order}
    for item in article_list:
        ai = item.get("ai_analysis", {}) or {}
        loc = ai.get("main_location", "Others")
        if ai.get("is_tech_news", False):
            loc = "Tech News"
        if loc not in grouped:
            loc = "Others"
        grouped[loc].append(item)
    return grouped

def rebuild_pool_from_preview(preview_list: list, selected_dict: dict, location_order: list) -> dict:
    """pool = preview_grouped - selected (by uid)."""
    pool = build_grouped_data(preview_list, location_order)
    selected_uids = set()
    for loc, items in (selected_dict or {}).items():
        for a in items:
            selected_uids.add(article_uid(a))

    for loc in list(pool.keys()):
        pool[loc] = [a for a in pool[loc] if article_uid(a) not in selected_uids]
    return pool

# ğŸ”¥ âœ… æ¢å¾©é€²åº¦å‡½æ•¸ï¼ˆæ–°å¢ï¼‰
def restore_progress(stage):
    """ä¸€éµæ¢å¾©æŒ‡å®šéšæ®µçš„é€²åº¦"""
    if stage == "ui_sorting":
        # 1) restore selected
        st.session_state.intl_sorted_dict = fb_logger.load_json_from_date_folder("user_final_list.json", {})
        st.session_state.intl_stage = "ui_sorting"

        # 2) rebuild pool from preview - selected
        preview_list = fb_logger.load_json_from_date_folder("preview_articles.json", [])
        location_order = LOCATION_ORDER

        st.session_state.intl_pool_dict = rebuild_pool_from_preview(
            preview_list=preview_list,
            selected_dict=st.session_state.intl_sorted_dict,
            location_order=location_order,
        )

    elif stage == "finished":
        st.session_state.intl_final_articles = fb_logger.load_json_from_date_folder("full_scraped_articles.json", [])
        st.session_state.intl_final_docx = None
        st.session_state.intl_stage = "finished"

    st.rerun()

# # ğŸ”¥ æ¢å¾©é€²åº¦å‡½æ•¸
# def restore_progress(stage):
#     """ä¸€éµæ¢å¾©æŒ‡å®šéšæ®µçš„é€²åº¦"""
#     if stage == "ui_sorting":
#         st.session_state.intl_sorted_dict = fb_logger.load_json_from_date_folder('user_final_list.json', {})
#         st.session_state.intl_stage = "ui_sorting"
#     elif stage == "finished":
#         st.session_state.intl_final_articles = fb_logger.load_json_from_date_folder('full_scraped_articles.json', [])
#         st.session_state.intl_final_docx = None  # éœ€è¦é‡æ–°ç”Ÿæˆä¸‹è¼‰éˆæ¥
#         st.session_state.intl_stage = "finished"
#     st.rerun()

def move_article(location, index, direction):
    """Move article up or down within its category"""
    articles = st.session_state.intl_sorted_dict[location]
    if direction == 'up' and index > 0:
        articles[index], articles[index-1] = articles[index-1], articles[index]
    elif direction == 'down' and index < len(articles) - 1:
        articles[index], articles[index+1] = articles[index+1], articles[index]
    st.session_state.intl_last_update = time.time() # Force rerun

def delete_article(location, index):
    """Remove article from list"""
    st.session_state.intl_sorted_dict[location].pop(index)
    st.session_state.intl_last_update = time.time()

def move_to_top(location, index):
    """Move article to top of its list"""
    articles = st.session_state.intl_sorted_dict[location]
    if index > 0:
        article = articles.pop(index)
        articles.insert(0, article)
        st.session_state.intl_last_update = time.time()

def add_to_selected(location: str, pool_index: int):
    """Move from pool -> selected."""
    article = st.session_state.intl_pool_dict[location].pop(pool_index)
    st.session_state.intl_sorted_dict.setdefault(location, []).append(article)
    st.session_state.intl_last_update = time.time()

def remove_to_pool(location: str, selected_index: int):
    """Move from selected -> pool."""
    article = st.session_state.intl_sorted_dict[location].pop(selected_index)
    st.session_state.intl_pool_dict.setdefault(location, []).append(article)
    st.session_state.intl_last_update = time.time()


def render_article_card(article, index, location, total_count, mode: str):
    """
    mode:
      - "selected": show up/down/top + åˆ é™¤(ç§»å›å€™é€‰æ± )
      - "pool": show æ·»åŠ 
    """
    score = article.get("ai_analysis", {}).get("overall_score", 0)
    color = "#ff4b4b" if score >= 20 else "#ffa500" if score >= 10 else "#21c354"

    card_style = """
    <style>
    .article-card {
        background-color: #0f172a10;
        border-radius: 10px;
        padding: 12px;
        margin-bottom: 10px;
        border-left: 5px solid %s;
    }
    .article-meta { font-size: 0.85em; opacity: 0.85; }
    </style>
    """
    st.markdown(card_style % color, unsafe_allow_html=True)

    uid = article_uid(article)
    keybase = f"{location}-{uid}-{mode}"

    with st.container():
        col1, col2 = st.columns([0.85, 0.15])
        with col1:
            prefix = f"{index + 1}. " if mode == "selected" else ""
            st.markdown(f"**{prefix}{article.get('title','(no title)')}**")
        with col2:
            st.caption(f"Score: {score}")

        meta_text = article.get("formatted_metadata") or "No metadata"
        st.markdown(f"<div class='article-meta'>{meta_text}</div>", unsafe_allow_html=True)

        with st.expander("æŸ¥çœ‹æ‘˜è¦å…§å®¹"):
            content = article.get("hover_text", "No content")
            st.markdown(content)

        if mode == "selected":
            c1, c2, c3, c4 = st.columns(4)
            with c1:
                if index > 0:
                    st.button("â†‘", key=f"up-{keybase}", on_click=move_article, args=(location, index, "up"))
            with c2:
                if index < total_count - 1:
                    st.button("â†“", key=f"down-{keybase}", on_click=move_article, args=(location, index, "down"))
            with c3:
                if index > 0:
                    st.button("ç½®é¡¶", key=f"top-{keybase}", on_click=move_to_top, args=(location, index))
            with c4:
                st.button("åˆ é™¤", key=f"rm-{keybase}", type="secondary", on_click=remove_to_pool, args=(location, index))
        else:
            st.button("æ·»åŠ ", key=f"add-{keybase}", type="primary", on_click=add_to_selected, args=(location, index))

    st.markdown("---")


# === Docx Trimming Function ===
def trim_docx_bytes_with_userlist(docx_bytes: bytes, user_final_list_dict: dict, keep_body_paras: int = 3) -> bytes:
    if not docx_bytes:
        raise ValueError("docx_bytes is empty")
    if not isinstance(user_final_list_dict, dict):
        raise ValueError("user_final_list_dict must be dict")

    tmp_in = tempfile.NamedTemporaryFile(delete=False, suffix=".docx")
    tmp_js = tempfile.NamedTemporaryFile(delete=False, suffix=".json")
    try:
        tmp_in.write(docx_bytes)
        tmp_in.close()

        tmp_js.write(json.dumps(user_final_list_dict, ensure_ascii=False).encode("utf-8"))
        tmp_js.close()

        tmp_out_path = tmp_in.name.replace(".docx", "_trimmed.docx")
        trim_docx(tmp_in.name, tmp_js.name, tmp_out_path, keep_body_paras=keep_body_paras)

        with open(tmp_out_path, "rb") as f:
            return f.read()
    finally:
        for p in [tmp_in.name, tmp_js.name, tmp_in.name.replace(".docx", "_trimmed.docx")]:
            try:
                os.remove(p)
            except:
                pass


def ensure_trimmed_docx_in_firebase_and_session(fb_logger):
    import streamlit as st

    if st.session_state.get("intl_final_docx_trimmed"):
        return

    # 1) å…ˆä» Firebase ç›´æ¥æ‹¿ trimmed
    trimmed_bytes = fb_logger.load_final_docx_from_date_folder("final_report_trimmed.docx")
    if trimmed_bytes:
        st.session_state.intl_final_docx_trimmed = trimmed_bytes
        return

    # 2) æ²¡æœ‰ trimmedï¼Œå°±ç”¨ final_report + user_final_list ç°åœºç”Ÿæˆ
    base_docx = st.session_state.get("intl_final_docx") or fb_logger.load_final_docx_from_date_folder("final_report.docx")
    if not base_docx:
        raise RuntimeError("Cannot load final_report.docx from session or Firebase")

    user_final_list = fb_logger.load_json_from_date_folder("user_final_list.json", {})
    if not user_final_list:
        raise RuntimeError("Cannot load user_final_list.json from Firebase")

    trimmed_bytes = trim_docx_bytes_with_userlist(base_docx, user_final_list, keep_body_paras=3)

    # 3) å›å­˜ Firebase + å†™ session
    fb_logger.save_final_docx_bytes_to_date_folder(trimmed_bytes, "final_report_trimmed.docx")
    st.session_state.intl_final_docx_trimmed = trimmed_bytes


# === ä¸»æµç¨‹å‡½æ•¸ ===

def _handle_international_news_logic(
    group_name_intl, username_intl, password_intl, api_key_intl,
    run_headless_intl, keep_browser_open_intl, max_words, min_words, max_articles
):
    """
    Revised flow with Firebase persistence + Mobile-First UI
    """
    
    global TODAY
    TODAY = datetime.now(HKT).strftime("%Y%m%d")  # æ›´æ–° TODAY

    # ğŸ”¥ âœ… æ™ºèƒ½æª¢æŸ¥ä»Šæ—¥é€²åº¦å‡½æ•¸ï¼ˆæ–°å¢ï¼‰
    def check_today_progress():
        """æª¢æŸ¥ Firebase ä¸­ä»Šæ—¥ä¸‰å€‹æ–‡ä»¶çš„å­˜åœ¨ç‹€æ…‹"""
        preview_exists = bool(fb_logger.load_json_from_date_folder('preview_articles.json', []))
        user_list_exists = bool(fb_logger.load_json_from_date_folder('user_final_list.json', {}))
        final_articles_exists = bool(fb_logger.load_json_from_date_folder('full_scraped_articles.json', []))
        
        total_preview = len(fb_logger.load_json_from_date_folder('preview_articles.json', []))
        total_user_list = sum(len(v) for v in fb_logger.load_json_from_date_folder('user_final_list.json', {}).values())
        
        return {
            'preview': preview_exists,
            'user_list': user_list_exists,
            'final_articles': final_articles_exists,
            'preview_count': total_preview,
            'user_list_count': total_user_list
        }



    # âœ… ç¢ºä¿ fb_logger å¯ç”¨ï¼ˆä¿ç•™åŸæœ‰çš„ï¼‰
    fb_logger = st.session_state.get('fb_logger') or ensure_logger(st, run_context="international_news")

    # # Locations Orderï¼ˆä¿ç•™åŸæœ‰çš„ï¼‰
    # LOCATION_ORDER = ['United States', 'Russia', 'Europe', 'Middle East', 
    #                   'Southeast Asia', 'Japan', 'Korea', 'China', 'Others', 'Tech News']

    # ğŸ”¥ âœ… æ™ºèƒ½é¦–é é‚è¼¯ï¼ˆæ–°å¢ï¼Œå®Œå…¨æ›¿æ›åŸé–‹é ­åˆå§‹åŒ–ï¼‰
    if "intl_stage" not in st.session_state:
        st.session_state.intl_stage = "smart_home"
    
    if st.session_state.intl_stage == "smart_home":
        st.header("ğŸŒ åœ‹éš›æ–°è - æ™ºèƒ½é€²åº¦æ¢å¾©")
        st.info(f"ğŸ“ Firebase: `international_news/{TODAY}/` | {datetime.now().strftime('%H:%M')}")
        
        # ğŸ”¥ æª¢æŸ¥é€²åº¦
        progress = check_today_progress()
        
        # ğŸ”¥ ç¾åŒ–é€²åº¦å„€è¡¨æ¿
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ğŸ“„ é è¦½æ–‡ç« ", f"{progress['preview_count']} ç¯‡", 
                    "âœ…" if progress['preview'] else "âŒ")
        with col2:
            st.metric("ğŸ‘¤ ç”¨æˆ¶æ’åº", f"{progress['user_list_count']} ç¯‡", 
                    "âœ…" if progress['user_list'] else "âŒ")
        with col3:
            st.metric("âœ… æœ€çµ‚å…¨æ–‡", f"{len(fb_logger.load_json_from_date_folder('full_scraped_articles.json', []))} ç¯‡", 
                    "âœ…" if progress['final_articles'] else "âŒ")
        
        st.divider()
        
        # ğŸ”¥ ä¸‰é¸ä¸€æŒ‰éˆ•ï¼ˆä¾å„ªå…ˆé †åºï¼‰
        if progress['final_articles']:  # 100% å®Œæˆ
            st.success("ğŸ‰ **ä»Šæ—¥ä»»å‹™å·²100%å®Œæˆï¼ç«‹å³ä¸‹è¼‰æœ€çµ‚å ±å‘Š**")
            if st.button("ğŸ“¥ ä¸‹è¼‰æœ€çµ‚ Word å ±å‘Šï¼ˆ100%é€²åº¦ï¼‰", type="primary", use_container_width=True):
                restore_progress("finished")
        elif progress['user_list']:     # 50% æ’åºå®Œæˆ
            st.warning("â³ **ä»Šæ—¥å·²å®Œæˆ50%ï¼ˆç”¨æˆ¶æ’åºï¼‰ï¼Œç¹¼çºŒå…¨æ–‡çˆ¬å–**")
            if st.button("ğŸ‘¤ æ¢å¾©æ’åºç•Œé¢ç¹¼çºŒï¼ˆ50%é€²åº¦ï¼‰", type="primary", use_container_width=True):
                restore_progress("ui_sorting")
        elif progress['preview']:       # 25% é è¦½å®Œæˆ
            st.info(f"ğŸ§  AI æ‡¸æµ®é è¦½å·²å®Œæˆ ({progress['preview_count']} ç¯‡æ–‡ç« )")
            if st.button(f"ğŸ¯ å±•ç¤ºç›®å‰é è¦½é€²åº¦ ({progress['preview_count']} æ¢)", type="secondary", use_container_width=True):
                # âœ… è¼‰å…¥é è¦½ JSONï¼ˆå·²å« AI åˆ†æï¼‰
                preview_list = fb_logger.load_json_from_date_folder('preview_articles.json', [])
                st.session_state.intl_articles_list = preview_list
                
                # âœ… è¤‡è£½ init éšæ®µçš„åˆ†çµ„é‚è¼¯ï¼Œç›´æ¥å¾ preview_list ç”Ÿæˆ sorted_dict
                # LOCATION_ORDER = [
                #     "United States", "Russia", "Europe", "Middle East", 
                #     "Southeast Asia", "Japan", "Korea", "China", "Others", "Tech News"
                # ]
                grouped_data = {loc: [] for loc in LOCATION_ORDER}
                for item in preview_list:
                    loc = item.get('ai_analysis', {}).get('main_location', 'Others')
                    if item.get('ai_analysis', {}).get('is_tech_news', False):
                        loc = 'Tech News'
                    grouped_data.setdefault(loc, []).append(item)
                
                # 1) Pool = æ‰€æœ‰å€™é€‰
                st.session_state.intlpooldict = grouped_data

                # 2) Selected = é»˜è®¤å…¨ç©ºï¼ˆä½† key è¦é½å…¨ï¼Œé¿å… bool({}) == Falseï¼‰
                st.session_state.intlsorteddict = {loc: [] for loc in LOCATION_ORDER}

                # 3) ä»ç„¶å†™ userfinallist.jsonï¼ˆå­˜â€œå·²é€‰æ¸…å•â€ï¼‰
                fb_logger.savejsontodatefolder(st.session_state.intlsorteddict, "userfinallist.json")

                st.success("âœ… å·²è¿›å…¥é€‰æ‹©æ¨¡å¼ï¼šé»˜è®¤æœªé€‰æ‹©ï¼Œç‚¹å‡»ã€æ·»åŠ ã€åŠ å…¥å·²é€‰æ¸…å•ã€‚")
                st.session_state.intlstage = "uisorting"
                st.rerun()
        else:                           # 0% å…¨æ–°é–‹å§‹
            st.success("ğŸ†• **ä»Šæ—¥å…¨æ–°ä»»å‹™ï¼Œé–‹å§‹æŠ“å–é è¦½**")
            if st.button("ğŸš€ é–‹å§‹æ–°ä»»å‹™ï¼ˆ0%é€²åº¦ï¼‰", type="primary", use_container_width=True):
                st.session_state.intl_stage = "init"
                st.rerun()
        
        st.divider()
        
        # ğŸ”¥ å‚™ç”¨é¸é …ï¼ˆå°æŒ‰éˆ•ï¼‰
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            if st.button("ğŸ”„ å¿½ç•¥é€²åº¦é‡ä¾†", type="secondary"):
                for key in ['intl_stage', 'intl_sorted_dict', 'intl_final_articles', 'intl_articles_list']:
                    if key in st.session_state: del st.session_state[key]
                st.session_state.intl_stage = "init"
                st.rerun()
        with col_b:
            if st.button("ğŸ“‹ æŸ¥çœ‹ JSON æ•¸æ“š", type="secondary"):
                st.session_state.intl_stage = "data_viewer"
                st.rerun()
        
        st.stop()
    
    elif st.session_state.intl_stage == "data_viewer":
        st.header("ğŸ“‹ JSON æ•¸æ“šæª¢è¦–")
        if st.button("è¿”å›é€²åº¦é "):
            st.session_state.intl_stage = "smart_home"
            st.rerun()
        col1, col2, col3 = st.columns(3)
        with col1:
            st.json(fb_logger.load_json_from_date_folder('preview_articles.json', []))
        with col2:
            st.json(fb_logger.load_json_from_date_folder('user_final_list.json', {}))
        with col3:
            st.json(fb_logger.load_json_from_date_folder('full_scraped_articles.json', []))
        if st.button("è¿”å›é€²åº¦é "):
            st.session_state.intl_stage = "smart_home"
            st.rerun()
        st.stop()

    try:
        # === Stage 1: Login, Search, Preview, AI Analysis ===
        if st.session_state.intl_stage == "init":
            if st.button("ğŸš€ é–‹å§‹ä»»å‹™ï¼šæŠ“å–é è¦½ + AI åˆ†æ"):
                with st.spinner("ç¬¬ä¸€æ­¥ï¼šç™»éŒ„ Wisers ä¸¦æŠ“å–é è¦½..."):
                    driver = setup_webdriver(headless=run_headless_intl, st_module=st)
                    if not driver: st.stop()
                    
                    wait = WebDriverWait(driver, 20)
                    perform_login(driver=driver, wait=wait, group_name=group_name_intl, username=username_intl, password=password_intl, api_key=api_key_intl, st_module=st)
                    switch_language_to_traditional_chinese(driver=driver, wait=wait, st_module=st)
                    
                    run_international_news_task(driver=driver, wait=wait, st_module=st, max_articles=max_articles)
                    
                    

                    # Scrape hover popovers
                    rawlist = []  # åˆå§‹åŒ–
                    rawlist = scrape_hover_popovers(driver=driver, wait=wait, st_module=st) or []
                    if st: st.info(f"âœ… æŠ“å–äº† {len(rawlist)} ç¯‡æ‡¸åœé è¦½")

                    # Logout before filter
                    st.info("æš«æ™‚ç™»å‡ºä»¥é‡‹æ”¾ Session...")
                    try:
                        robust_logout_request(driver, st)
                    except Exception as e:
                        st.warning(f"ç™»å‡ºæ™‚å‡ºç¾å•é¡Œ: {e}")
                    driver.quit()

                    # Filter by word count from hover_text
                    filtered_rawlist = []
                    for item in rawlist:  # ç¾åœ¨ä¿è­‰ rawlist å­˜åœ¨
                        hover_text = item.get("hover_text", "")
                        word_matches = re.findall(r'(\d+)\s*å­—', hover_text)
                        if word_matches:
                            word_count = int(word_matches[0])
                            if min_words <= word_count <= max_words:
                                filtered_rawlist.append(item)
                            else:
                                if st: st.write(f"å·²éæ¿¾: {item.get('title', 'Unknown')} ({word_count} å­—)")
                        else:
                            # ç„¡å­—æ•¸ metadataï¼Œä¿ç•™
                            filtered_rawlist.append(item)

                    rawlist = filtered_rawlist
                    if st: st.info(f"ğŸ“Š å­—æ•¸éæ¿¾å¾Œå‰©é¤˜: {len(rawlist)} ç¯‡")


                    # Filter & AI Analysis
                    filtered_list = []
                    for i, item in enumerate(rawlist):
                        item['original_index'] = i
                        filtered_list.append(item)
                    
                    with st.spinner(f"ç¬¬äºŒæ­¥ï¼šAI æ­£åœ¨åˆ†æ {len(filtered_list)} ç¯‡æ–‡ç« ..."):
                        analyzed_list = run_ai_screening(
                            filtered_list,
                            progress_callback=lambda i, n, t: st.text(f"åˆ†æä¸­ ({i+1}/{n}): {t}...")
                        )
                    
                    for item in analyzed_list:
                        hover_text = item.get("hover_text", "")

                        # âœ… æ–°å¢ï¼šæå– news_id
                        hover_html = item.get('hover_html', '')
                        news_id = extract_news_id_from_html(hover_html)
                        item['news_id'] = news_id

                        if "\n" in hover_text:
                            lines = hover_text.split("\n", 2)
                            if len(lines) > 1 and lines[0].strip() == item.get("title", "").strip():
                                raw_meta = lines[1].strip()
                            else:
                                raw_meta = lines[0].strip()
                        else:
                            raw_meta = ""
                        
                        item["formatted_metadata"] = parse_metadata(raw_meta)

                    # Group by Location
                    grouped_data = {loc: [] for loc in LOCATION_ORDER}
                    for item in analyzed_list:
                        loc = item.get('ai_analysis', {}).get('main_location', 'Others')
                        if item.get('ai_analysis', {}).get('is_tech_news', False):
                            loc = 'Tech News'
                        if loc not in grouped_data: loc = 'Others'
                        grouped_data[loc].append(item)
                    
                    # âœ… æŠŠæœ€ç»ˆå¸¦æœ‰ hover æ‘˜è¦ + AI åˆ†æçš„æ•°æ®ï¼Œå†™å› session
                    st.session_state.intl_articles_list = analyzed_list

                    # âœ… æ‚¬æµ®é¢„è§ˆ + AI å®Œæˆåå†ä¿å­˜ preview_articles.json
                    fb_logger.save_json_to_date_folder(
                        st.session_state.intl_articles_list,
                        'preview_articles.json'
                    )

                    st.session_state.intl_sorted_dict = grouped_data
                    st.session_state.intl_stage = "ui_sorting"
                    st.rerun()

        # === Stage 2: UI Sortingï¼ˆè‡ªå‹•ä¿å­˜ï¼‰ ===
        if st.session_state.intl_stage == "ui_sorting":
            st.header("ğŸ“± æ–°èæ’åºèˆ‡ç¯©é¸")
            st.info(f"ğŸ’¾ è‡ªå‹•ä¿å­˜è‡³ Firebase: `international_news/{TODAY}/user_final_list.json`")
            
            # Global Actions
            col_g1, col_g2 = st.columns(2)
            with col_g1:
                if st.button("ğŸ”„ é‡æ–°é–‹å§‹ (æ¸…é™¤æ•¸æ“š)"):
                    st.session_state.intl_stage = "init"
                    st.rerun()
            with col_g2:
                if st.button("ğŸ’¾ æ‰‹å‹•ä¿å­˜æ’åº"):
                    fb_logger.save_json_to_date_folder(st.session_state.intl_sorted_dict, 'user_final_list.json')
                    st.success("âœ… å·²ä¿å­˜ç”¨æˆ¶æ’åºæ¸…å–®ï¼")

            st.write("---")
            
            # Calculate counts
            total_articles = sum(len(v) for v in st.session_state.intl_sorted_dict.values())
            st.markdown(f"**ç¸½æ–‡ç« æ•¸: {total_articles}**")

            # Render Categories
            for location in LOCATION_ORDER:
                articles = st.session_state.intl_sorted_dict.get(location, [])
                if not articles: continue
                
                with st.expander(f"{location} ({len(articles)})", expanded=True):
                    for i, article in enumerate(articles):
                        render_article_card(article, i, location, len(articles))

            st.write("---")
            
            # âœ… é—œéµï¼šç¢ºèªå‰è‡ªå‹•ä¿å­˜
            if st.button("âœ… ç¢ºèªæ’åºä¸¦é–‹å§‹å…¨æ–‡çˆ¬å–", type="primary", use_container_width=True):
                fb_logger.save_json_to_date_folder(st.session_state.intl_sorted_dict, 'user_final_list.json')
                st.success("ğŸ’¾ ç”¨æˆ¶æ’åºå·²è‡ªå‹•ä¿å­˜è‡³ Firebase")
                st.session_state.intl_stage = "final_scraping"
                st.rerun()

        # === Stage 3: Final Scrape ===
        if st.session_state.intl_stage == "final_scraping":
            st.header("â³ æœ€çµ‚è™•ç†ä¸­...")
            
            # Flatten list
            final_list = []
            for loc in LOCATION_ORDER:
                if loc in st.session_state.intl_sorted_dict:
                    final_list.extend(st.session_state.intl_sorted_dict[loc])
            
            if not final_list:
                st.warning("æ²’æœ‰æ–‡ç« è¢«é¸ä¸­ã€‚")
                if st.button("è¿”å›"):
                    st.session_state.intl_stage = "ui_sorting"
                    st.rerun()
                st.stop()

            with st.spinner(f"æ­£åœ¨çˆ¬å– {len(final_list)} ç¯‡æ–‡ç« çš„å…¨æ–‡å…§å®¹..."):
                try:
                    driver = setup_webdriver(headless=run_headless_intl, st_module=st)
                    wait = WebDriverWait(driver, 20)
                    perform_login(driver=driver, wait=wait, group_name=group_name_intl, username=username_intl, password=password_intl, api_key=api_key_intl, st_module=st)
                    switch_language_to_traditional_chinese(driver=driver, wait=wait, st_module=st)
                    
                    
                    # âœ… é‡æ–°æœç´¢ä»¥æ˜¾ç¤ºç»“æœé¡µï¼ˆä½†ä¸å†ä¾èµ–ç´¢å¼•ï¼‰
                    run_international_news_task(driver=driver, wait=wait, st_module=st)
                    
                    # âœ… ä½¿ç”¨æ–°å‡½æ•°ï¼šæŒ‰ news_id/æ ‡é¢˜å®šä½è€Œéç´¢å¼•
                    full_articles_data = scrape_articles_by_news_id(driver, wait, final_list, st_module=st)
                    
                    # âœ… ä¿å­˜æœ€çµ‚çˆ¬å–çµæœ
                    st.session_state.intl_final_articles = full_articles_data
                    fb_logger.save_json_to_date_folder(full_articles_data, 'full_scraped_articles.json')
                    
                    # Generate Docx
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
                        out_path = create_international_news_report(
                            articles_data=full_articles_data,
                            output_path=tmp.name,
                            st_module=st
                        )
                        with open(out_path, "rb") as f:
                            file_data = f.read()

                    st.session_state.intl_final_docx = file_data

                    # âœ… é€™è£¡ä¿å­˜ final_report åˆ° Firebase
                    fb_logger.save_final_docx_to_date_folder(full_articles_data, 'final_report.docx')

                    # âœ… ç”Ÿæˆ trimmed + ä¿å­˜åˆ° Firebase + æ”¾è¿› session
                    user_final_list = fb_logger.load_json_from_date_folder("user_final_list.json", {})
                    trimmed_bytes = trim_docx_bytes_with_userlist(st.session_state.intl_final_docx, user_final_list, keep_body_paras=3)

                    fb_logger.save_final_docx_bytes_to_date_folder(trimmed_bytes, "final_report_trimmed.docx")
                    st.session_state.intl_final_docx_trimmed = trimmed_bytes

                    st.session_state.intl_stage = "finished"
                    robust_logout_request(driver, st)
                    driver.quit()
                    st.rerun()

                    
                    
                except Exception as e:
                    st.error(f"çˆ¬å–å¤±æ•—: {e}")
                    if st.button("é‡è©¦"):
                        st.rerun()

        # === Stage 4: Downloadï¼ˆå®Œå…¨æ›¿æ›ï¼‰ ===
        if st.session_state.intl_stage == "finished":
            st.header("ğŸ‰ ä»»å‹™å…¨éƒ¨å®Œæˆï¼")
            
            # ğŸ”¥ æ™ºèƒ½é‡æ–°ç”Ÿæˆ/è¼‰å…¥ DOCX
            if 'intl_final_docx' not in st.session_state or not st.session_state.intl_final_docx:
                with st.spinner("ğŸ”„ å¾ Firebase é‡æ–°ç”Ÿæˆä¸‹è¼‰æ–‡ä»¶..."):
                    # å„ªå…ˆå¾å·²ä¿å­˜çš„ DOCX æ–‡ä»¶è¼‰å…¥
                    docx_bytes = fb_logger.load_final_docx_from_date_folder('final_report.docx')
                    if not docx_bytes:
                        # å‚™ç”¨æ–¹æ¡ˆï¼šå¾æ–‡ç« æ•¸æ“šé‡æ–°ç”Ÿæˆ
                        final_articles = st.session_state.get('intl_final_articles', fb_logger.load_json_from_date_folder('full_scraped_articles.json', []))
                        if final_articles:
                            docx_bytes = fb_logger.save_final_docx_to_date_folder(final_articles, 'final_report.docx')
                            docx_bytes = fb_logger.load_final_docx_from_date_folder('final_report.docx')
                    
                    if docx_bytes:
                        st.session_state.intl_final_docx = docx_bytes
                    else:
                        st.error("âŒ ç„¡æ³•æ¢å¾©æœ€çµ‚å ±å‘Šï¼Œè«‹é‡æ–°åŸ·è¡Œçˆ¬å–")
                        st.stop()
            
            # --- ç¡®ä¿ trimmed å·²æ¢å¤/å·²ç”Ÿæˆ ---
            ensure_trimmed_docx_in_firebase_and_session(fb_logger)

            # ğŸ”¥ ä¸‹è¼‰æŒ‰éˆ•
            colA, colB = st.columns(2)

            with colA:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰æœ€çµ‚ Word å ±å‘Š",
                    data=st.session_state.intl_final_docx,
                    file_name=f"Intl_News_Report_{TODAY}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    type="primary",
                    use_container_width=True,
                    help="åŒ…å«ä»Šæ—¥æœ€çµ‚æ’åºçš„å®Œæ•´æ–°èå ±å‘Š"
                )

            with colB:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰ï¼ˆä¸‰æ®µç‰ˆï¼‰Word å ±å‘Š",
                    data=st.session_state.intl_final_docx_trimmed,
                    file_name=f"Intl_News_Report_{TODAY}_trimmed.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    type="secondary",
                    use_container_width=True,
                    help="æ¯ç¯‡ï¼šæ¨™é¡Œ + metadata + æ­£æ–‡ä¸‰æ®µï¼ˆå‰¯æ¨™é¡Œä¸ä½”æ®µæ•¸ï¼‰"
                )


            # ğŸ”¥ é€²åº¦æ‘˜è¦
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ç¸½æ–‡ç« æ•¸", len(st.session_state.get('intl_final_articles', [])))
            with col2:
                st.metric("Firebase ç‹€æ…‹", "âœ… å®Œæ•´å‚™ä»½")
            
            st.success(f"ğŸ’¾ å®Œæ•´å‚™ä»½: `international_news/{TODAY}/`")
            
            if st.button("ğŸ”„ é–‹å§‹æ–°ä»»å‹™"):
                st.session_state.intl_stage = "smart_home"
                st.rerun()

    except Exception as e:
        st.error(f"ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
        st.code(traceback.format_exc())


def render_international_news_tab():
    """
    Render the International News tab content
    """
    st.header("International News")
    
    # 1. ç²å–æ†‘è­‰ (é€™éƒ¨åˆ†é‚è¼¯å¾åŸä¾†çš„ international_news.py æ¬éä¾†)
    # Helper to get credentials
    def _get_credentials_intl():
        try:
            group_name = st.secrets["wisers"]["group_name"]
            username = st.secrets["wisers"]["username"]
            password = st.secrets["wisers"]["password"]
            return group_name, username, password
        except:
            return None, None, None

    def _get_api_key_intl():
        try:
            return st.secrets["wisers"]["api_key"]
        except:
            return None

    # Sidebar Options
    with st.sidebar:
        st.subheader("International News Settings")
        max_words = st.slider("Max Words", 200, 2000, 1000)
        min_words = st.slider("Min Words", 50, 500, 200)
        max_articles = st.slider("Max Articles", 10, 100, 30)
        run_headless = st.checkbox("Headless Mode", value=True)
        keep_open = st.checkbox("Keep Browser Open", value=False)
        
        # Credentials Input (Fallback)
        group, user, pwd = _get_credentials_intl()
        api_key = _get_api_key_intl()
        
        if not all([group, user, pwd, api_key]):
            st.warning("è«‹åœ¨ secrets.toml é…ç½®æ†‘è­‰ï¼Œæˆ–åœ¨æ­¤è¼¸å…¥ï¼š")
            group = st.text_input("Group", value=group or "")
            user = st.text_input("User", value=user or "")
            pwd = st.text_input("Password", type="password", value=pwd or "")
            api_key = st.text_input("2Captcha Key", type="password", value=api_key or "")

    # 2. åŸ·è¡Œä¸»é‚è¼¯
    if all([group, user, pwd, api_key]):
        _handle_international_news_logic(
            group, user, pwd, api_key,
            run_headless, keep_open, max_words, min_words, max_articles
        )
    else:
        st.error("è«‹æä¾›å®Œæ•´çš„ Wisers å¸³è™Ÿå¯†ç¢¼åŠ API Key æ‰èƒ½é–‹å§‹ã€‚")
